status: "accepted"

decision-makers: Denis Smirnov

--------------------------------

# Архитектура исполнителя

## Описание проблемы

На текущий момент PostgreSQL имеет только построчный
движок на архитектуре Vulcano. Это хорошее решение для OLTP,
но оно не годится для аналитики. Все современные OLAP движки
используют при обработке колоночное представление данных в
памяти (чтобы получить SIMD и локальность данных в кэше ЦПУ).

Помимо этого, PostgreSQL живет на процессной модели, где каждый
процесс исполняет единственный поток. Проблема в том, что эти
потоки занимаются не только обработкой данных, но и I/O: поднимают
с диска блоки в общий кэш внутри общей памяти, общаются
с клиентом по сети. Это приводит к тому, что планировщик ОС
снимает потоки с ядер (а потом возвращает их обратно, что
плохо для TLB).

Все это делает вычисления исторической аналитики на PostgreSQL
очень медленным мероприятием: ClickHouse посчитает все на
порядок быстрее. В результате есть гипотеза, что пользователям
нужен эффективный по ЦПУ движок внутри PostgreSQL, который
мог бы радикально ускорить большую часть читающих запросов
для heap таблиц.

## Факторы принятия решения

1. Разработка должна требовать минимум возможных ресурсов.
   Следствий тут два.
   - Движок должен поставляться в виде расширения. Свой
     форк - это очень дорого, а хуки позволяют без проблем
     встроить CustomScan узел, исполняемый своим движком.
   - Разработка должна вестись на rust.
     - Безопасность. Скомпилированный код не содержит
       типовых ошибок по работе с памятью или многозадачностью.
     - Есть богатая инфраструктура готовых пакетов (в т.ч.
       pgrx для разработки расширений для PostgreSQL).
     - Это модный язык, который многие захотят попробовать
       (привлечение сторонних разработчиков в проект).
2. Движок нужно брать готовый. Писать SQL движок с нуля
   дорого и не нужно: на рынке есть варианты, которые
   можно взять и встроить внутрь PostgreSQL.
3. Движок должен быть на rust (раз мы разрабатываем на этом
   языке).
4. Движок должен быть расширяемый, чтобы иметь возможность
   подкрутить нужные нам вещи в ходе разрабоки без форка
   движка (поддерживать не хватит ресурсов).

## Рассматриваемые варианты

При описанных выше вводных вариант остается только один:
использовать DataFusion. Других расширяемых SQL движков
под аналитику (и проверенных в бою) для rust сейчас нет.
Тем более, что DataFusion уже умеет довольно неплохое
подмножество SQL из PostgreSQL диалекта.

## Реализация

Важно учитывать, что DataFusion плотно прибит гвоздями к
асинхронному рантайту tokio, реализующему кооперативную
многозадачность на множестве потоков (все внутри одного
процесса). При этом PostgreSQL порождает отдельный процесс
под каждого пользователя.

### Исполнитель

1. Расширение с DataFusion подгружается при старте кластера
   через `shared_preload_libraries`.
2. Postmaster при старте создает bgworker, в котором запускается
   event loop рантайма tokio, выполняющий код DataFusion.
3. Bgworker соединяется через общую память со всеми бекендами.
   Суть в том, что потоки внутри bgworker никогда не работают с
   I/O и планировщик ОС не снимет их с ядер. Все I/O останется
   внутри бекендов клиентов, которые будут через общую память
   обмениваться сообщениями с DataFusion:
   ```
   -> выполни запрос
   <- дай метаданные
   -> вот метаданные из каталога
   <- загрузи мне в кэш и запинь блок от таблицы
   -> сделано, милорд
   ...
   <- вот первая порция данных в общей памяти
   ...
   <- запрос исполнен
   ```
   По сути, это подход Tarantool, только в последнем единственный
   транзакционный поток (а не пул как в tokio).
4. Бекенды выступают как клиенты и подключаются через собственный
   протокол поверх очередей в общей памяти к bgworker с DataFusion.
5. ...
6. PROFIT!

При этом нужно учитывать, что каждый блок heap таблицы должен быть
скопирован и перепакован в arrow для DataFusion. При перепаковке
необходимо применить функции проверки видимости кортежей из ядра
PostgreSQL.

### Планировщик

Идеально было бы, конечно, позволять строить план PostgreSQL,
а потом его узлы транслировать в физический план внутри DataFusion.
Но я примерился к такому подходу и реализовать его будет слишком
сложно (возможно, никогда-нибудь). Поэтому пока будет использовать
DataFusion и прокачивать его собственным кодом и статистикой из
PostgreSQL (но история с использованием данных из pg_stats заслуживает
отдельный ADR).

## Плюсы и минусы

Плюсы:
1. Потенциально отличная производительность ЦПУ.
2. Быстрая разработка (безопасный по памяти язык, готовые запчасти).
3. Возможность вовлечения других разработчиков, когда будет сделана
   PostgreSQL специфичная работа и дальше будет чистый rust, tokio
   и DataFusion.

Минусы:
1. Нужно быть аккуратным, если кто-то убьет bgworker с DataFusion
   (общая память, отмена запросов на бекендах). На первом этапе
   можно складывать кластер домиком.
2. Придется в перспективе прокачивать планировщик DataFusion.
3. Нужно создать протокол сообщений между бекендами и bgworker
   с транспортом поверх общей памяти.


## Дополнительная информация

Существует сходный проект от разработчиков DuckDB:
> https://github.com/motherduckdb/pg_duckdb

Его главные отличия:
1. Разработчикам не нужен модульный движок (они сами пилят DuckDB)
2. DuckDB встраивается в каждый бекенд и его потоки бокируются по
   I/O.
3. Богомерзкий C++ (так как на нем написан сам DuckDB).

Но вещь очень полезная, чтобы подсматривать реализацию части
функционала (перепаковка блоков, как самое важное).
